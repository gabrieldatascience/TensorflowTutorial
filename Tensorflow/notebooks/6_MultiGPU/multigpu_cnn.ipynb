{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi-GPU Training Ejemplo\n",
    "\n",
    "Entrena una red neuronal convolucional en múltiples GPUs con TensorFlow.\n",
    "\n",
    "Este ejemplo utiliza capas de TensorFlow, ver 'convolutional_network_raw' ejemplo\n",
    "para una implementación de TensorFlow con variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Formación con múltiples tarjetas GPU\n",
    "\n",
    "En este ejemplo, estamos utilizando el paralelismo de datos para dividir el entrenamiento en varias GPUs. Cada GPU tiene una réplica completa del modelo de red neuronal, y los pesos (es decir, las variables) se actualizan de forma sincrónica a la espera de que cada GPU procese su lote de datos.\n",
    "\n",
    "En primer lugar, cada GPU procesa un lote distinto de datos y calcula los degradados correspondientes; a continuación, todos los degradados se acumulan en la CPU y se promedian. Los pesos de los modelos se actualizan finalmente con los gradientes promediados, y los nuevos pesos de los modelos se devuelven a cada GPU para repetir el proceso de formación.\n",
    "\n",
    "<img src=\"https://www.tensorflow.org/images/Parallelism.png\" alt=\"Parallelism\" style=\"width: 400px;\"/>\n",
    "\n",
    "## MNIST Descripción general del conjunto de datos\n",
    "\n",
    "Este ejemplo utiliza dígitos manuscritos MNIST. El conjunto de datos contiene 60.000 ejemplos de formación y 10.000 ejemplos de pruebas. Los dígitos han sido normalizados y centrados en una imagen de tamaño fijo (28x28 píxeles) con valores de 0 a 1. Para simplificar, cada imagen ha sido aplanada y convertida a una matriz numérica 1-D de 784 características (28*28).\n",
    "\n",
    "![MNIST Dataset](http://neuralnetworksanddeeplearning.com/images/mnist_100_digits.png)\n",
    "\n",
    "Más información: http://yann.lecun.com/exdb/mnist/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /tmp/data/train-images-idx3-ubyte.gz\n",
      "Extracting /tmp/data/train-labels-idx1-ubyte.gz\n",
      "Extracting /tmp/data/t10k-images-idx3-ubyte.gz\n",
      "Extracting /tmp/data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import time\n",
    "\n",
    "# Importar datos MNIST\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"/tmp/data/\", one_hot=True)\n",
    "\n",
    "# Parametros\n",
    "num_gpus = 2\n",
    "num_steps = 200\n",
    "learning_rate = 0.001\n",
    "batch_size = 1024\n",
    "display_step = 10\n",
    "\n",
    "# Network Parametros\n",
    "num_input = 784 # Entrada de datos MNIST (forma de la imagen: 28*28)\n",
    "num_classes = 10 # Total de clases MNIST (0-9 dígitos)\n",
    "dropout = 0.75 # Abandono, probabilidad de mantener las unidades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Construir una convolutional neural network\n",
    "def conv_net(x, n_classes, dropout, reuse, is_training):\n",
    "    # Definir un ámbito de reutilización de las variables\n",
    "    with tf.variable_scope('ConvNet', reuse=reuse):\n",
    "        # La entrada de datos MNIST es un vector 1-D de 784 características (28*28 píxeles)\n",
    "        # Modificar para que coincida con el formato de la imagen[Altura x Anchura x Canal]\n",
    "        # La entrada del tensor se convierte en 4-D:[Tamaño del lote, altura, ancho, canal]\n",
    "        x = tf.reshape(x, shape=[-1, 28, 28, 1])\n",
    "\n",
    "        # Capa de convolución con 64 filtros y un tamaño de núcleo de 5\n",
    "        x = tf.layers.conv2d(x, 64, 5, activation=tf.nn.relu)\n",
    "        # Agrupación máxima (muestreo descendente) con zancadas de 2 y tamaño de kernel de 2\n",
    "        x = tf.layers.max_pooling2d(x, 2, 2)\n",
    "\n",
    "        # Capa de convolución con 256 filtros y un tamaño de núcleo de 5\n",
    "        x = tf.layers.conv2d(x, 256, 3, activation=tf.nn.relu)\n",
    "        # Capa de convolución con 512 filtros y un tamaño de núcleo de 5\n",
    "        x = tf.layers.conv2d(x, 512, 3, activation=tf.nn.relu)\n",
    "        # Agrupación máxima (muestreo descendente) con zancadas de 2 y tamaño de kernel de 2\n",
    "        x = tf.layers.max_pooling2d(x, 2, 2)\n",
    "\n",
    "        # Aplanar los datos a un vector 1-D para la capa completamente conectada.\n",
    "        x = tf.contrib.layers.flatten(x)\n",
    "\n",
    "        # Capa completamente conectada (en la carpeta contrib por ahora)\n",
    "        x = tf.layers.dense(x, 2048)\n",
    "        # Aplicar Abandono (si is_training es Falso, no se aplica el abandono)\n",
    "        x = tf.layers.dropout(x, rate=dropout, training=is_training)\n",
    "\n",
    "        # Capa completamente conectada (en la carpeta contrib por ahora)\n",
    "        x = tf.layers.dense(x, 1024)\n",
    "        # Aplicar Abandono (si is_training es Falso, no se aplica el abandono)\n",
    "        x = tf.layers.dropout(x, rate=dropout, training=is_training)\n",
    "\n",
    "        # Capa de salida, predicción de clases\n",
    "        out = tf.layers.dense(x, n_classes)\n",
    "        # Porque la pérdida de'softmax_cross_entropy_with_logits' ya se aplica\n",
    "        # softmax, sólo aplicamos softmax a la red de pruebas\n",
    "        out = tf.nn.softmax(out) if not is_training else out\n",
    "\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Construya la función para promediar los gradientes\n",
    "def average_gradients(tower_grads):\n",
    "    average_grads = []\n",
    "    for grad_and_vars in zip(*tower_grads):\n",
    "        # Tenga en cuenta que cada grad_y_vars tiene el siguiente aspecto:\n",
    "        # ((grad0_gpu0, var0_gpu0), .... (grad0_gpuN, var0_gpuN))\n",
    "        grads = []\n",
    "        for g, _ in grad_and_vars:\n",
    "            # Añada la dimensión 0 a los gradientes para representar la torre.\n",
    "            expanded_g = tf.expand_dims(g, 0)\n",
    "\n",
    "            # Añada una dimensión de \"torre\" que promediamos a continuación.\n",
    "            grads.append(expanded_g)\n",
    "\n",
    "        # Promedio sobre la dimensión 'torre'.\n",
    "        grad = tf.concat(grads, 0)\n",
    "        grad = tf.reduce_mean(grad, 0)\n",
    "\n",
    "        # Tenga en cuenta que las Variables son redundantes porque son compartidas\n",
    "        # a través de las torres. Así que... simplemente devolveremos el puntero de la primera torre a\n",
    "        # la Variable.\n",
    "        v = grad_and_vars[0][1]\n",
    "        grad_and_var = (grad, v)\n",
    "        average_grads.append(grad_and_var)\n",
    "    return average_grads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Por defecto, todas las variables se colocarán en '/gpu:0''.\n",
    "# Así que necesitamos una función de dispositivo personalizada, para asignar todas las variables a'/cpu:0'.\n",
    "# Nota: Si se utilizan GPUs, '/gpu:0' puede ser una opción más rápida.\n",
    "PS_OPS = ['Variable', 'VariableV2', 'AutoReloadVariable']\n",
    "\n",
    "def assign_to_device(device, ps_device='/cpu:0'):\n",
    "    def _assign(op):\n",
    "        node_def = op if isinstance(op, tf.NodeDef) else op.node_def\n",
    "        if node_def.op in PS_OPS:\n",
    "            return \"/\" + ps_device\n",
    "        else:\n",
    "            return device\n",
    "\n",
    "    return _assign"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1: Minibatch Loss= 2.4077, Training Accuracy= 0.123, 682 Examples/sec\n",
      "Step 10: Minibatch Loss= 1.0067, Training Accuracy= 0.765, 6528 Examples/sec\n",
      "Step 20: Minibatch Loss= 0.2442, Training Accuracy= 0.945, 6803 Examples/sec\n",
      "Step 30: Minibatch Loss= 0.2013, Training Accuracy= 0.951, 6741 Examples/sec\n",
      "Step 40: Minibatch Loss= 0.1445, Training Accuracy= 0.962, 6700 Examples/sec\n",
      "Step 50: Minibatch Loss= 0.0940, Training Accuracy= 0.971, 6746 Examples/sec\n",
      "Step 60: Minibatch Loss= 0.0792, Training Accuracy= 0.977, 6627 Examples/sec\n",
      "Step 70: Minibatch Loss= 0.0593, Training Accuracy= 0.979, 6749 Examples/sec\n",
      "Step 80: Minibatch Loss= 0.0799, Training Accuracy= 0.984, 6368 Examples/sec\n",
      "Step 90: Minibatch Loss= 0.0614, Training Accuracy= 0.988, 6762 Examples/sec\n",
      "Step 100: Minibatch Loss= 0.0716, Training Accuracy= 0.983, 6338 Examples/sec\n",
      "Step 110: Minibatch Loss= 0.0531, Training Accuracy= 0.986, 6504 Examples/sec\n",
      "Step 120: Minibatch Loss= 0.0425, Training Accuracy= 0.990, 6721 Examples/sec\n",
      "Step 130: Minibatch Loss= 0.0473, Training Accuracy= 0.986, 6735 Examples/sec\n",
      "Step 140: Minibatch Loss= 0.0345, Training Accuracy= 0.991, 6636 Examples/sec\n",
      "Step 150: Minibatch Loss= 0.0419, Training Accuracy= 0.993, 6777 Examples/sec\n",
      "Step 160: Minibatch Loss= 0.0602, Training Accuracy= 0.984, 6392 Examples/sec\n",
      "Step 170: Minibatch Loss= 0.0425, Training Accuracy= 0.990, 6855 Examples/sec\n",
      "Step 180: Minibatch Loss= 0.0107, Training Accuracy= 0.998, 6804 Examples/sec\n",
      "Step 190: Minibatch Loss= 0.0204, Training Accuracy= 0.995, 6645 Examples/sec\n",
      "Step 200: Minibatch Loss= 0.0296, Training Accuracy= 0.993, 6747 Examples/sec\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.990671\n"
     ]
    }
   ],
   "source": [
    "# Poner todos los ops en la CPU por defecto\n",
    "with tf.device('/cpu:0'):\n",
    "    tower_grads = []\n",
    "    reuse_vars = False\n",
    "\n",
    "    # tf Entrada de gráficos\n",
    "    X = tf.placeholder(tf.float32, [None, num_input])\n",
    "    Y = tf.placeholder(tf.float32, [None, num_classes])\n",
    "\n",
    "    # Realice un bucle en todas las GPUs y construya su propio gráfico de cálculo.\n",
    "    for i in range(num_gpus):\n",
    "        with tf.device(assign_to_device('/gpu:{}'.format(i), ps_device='/cpu:0')):\n",
    "\n",
    "            # Divide los datos entre las GPUs\n",
    "            _x = X[i * batch_size: (i+1) * batch_size]\n",
    "            _y = Y[i * batch_size: (i+1) * batch_size]\n",
    "\n",
    "            # Debido a que los Abandonados tienen un comportamiento diferente en el entrenamiento y en el tiempo de predicción, nosotros\n",
    "            # necesitan crear 2 gráficos de cálculo distintos que compartan los mismos pesos.\n",
    "\n",
    "            # Cree un gráfico para el entrenamiento\n",
    "            logits_train = conv_net(_x, num_classes, dropout,\n",
    "                                    reuse=reuse_vars, is_training=True)\n",
    "            # Cree otro gráfico para probar que reutilice los mismos pesos\n",
    "            logits_test = conv_net(_x, num_classes, dropout,\n",
    "                                   reuse=True, is_training=False)\n",
    "\n",
    "            # Definir la pérdida y el optimizador (con los registros del tren, para que la pérdida de datos tenga efecto)\n",
    "            loss_op = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(\n",
    "                logits=logits_train, labels=_y))\n",
    "            optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)\n",
    "            grads = optimizer.compute_gradients(loss_op)\n",
    "\n",
    "            # Sólo la primera precisión de cálculo de la GPU\n",
    "            if i == 0:\n",
    "                # Evaluar el modelo (con registros de pruebas, para deshabilitar la deserción escolar)\n",
    "                correct_pred = tf.equal(tf.argmax(logits_test, 1), tf.argmax(_y, 1))\n",
    "                accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
    "\n",
    "            reuse_vars = True\n",
    "            tower_grads.append(grads)\n",
    "\n",
    "    tower_grads = average_gradients(tower_grads)\n",
    "    train_op = optimizer.apply_gradients(tower_grads)\n",
    "\n",
    "    # Inicialización de las variables\n",
    "    init = tf.global_variables_initializer()\n",
    "\n",
    "    # Iniciar el gráfico\n",
    "    with tf.Session() as sess:\n",
    "        sess.run(init)\n",
    "        step = 1\n",
    "        # Mantenga el entrenamiento hasta alcanzar las iteraciones máximas\n",
    "        for step in range(1, num_steps + 1):\n",
    "            # Obtén un lote por cada GPU\n",
    "            batch_x, batch_y = mnist.train.next_batch(batch_size * num_gpus)\n",
    "            # Optimización de la ejecución (backprop)\n",
    "            ts = time.time()\n",
    "            sess.run(train_op, feed_dict={X: batch_x, Y: batch_y})\n",
    "            te = time.time() - ts\n",
    "            if step % display_step == 0 or step == 1:\n",
    "                # Calcular la pérdida y la precisión de los lotes\n",
    "                loss, acc = sess.run([loss_op, accuracy], feed_dict={X: batch_x,\n",
    "                                                                     Y: batch_y})\n",
    "                print(\"Step \" + str(step) + \": Minibatch Loss= \" + \\\n",
    "                      \"{:.4f}\".format(loss) + \", Training Accuracy= \" + \\\n",
    "                      \"{:.3f}\".format(acc) + \", %i Examples/sec\" % int(len(batch_x)/te))\n",
    "            step += 1\n",
    "        print(\"Optimization Finished!\")\n",
    "\n",
    "        # Calcule la precisión para imágenes de prueba de 1000 mnist\n",
    "        print(\"Testing Accuracy:\", \\\n",
    "            np.mean([sess.run(accuracy, feed_dict={X: mnist.test.images[i:i+batch_size],\n",
    "            Y: mnist.test.labels[i:i+batch_size]}) for i in range(0, len(mnist.test.images), batch_size)]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
